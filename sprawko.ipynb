{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Funkcja ukrywająca wiadomość przy użyciu znaków o zerowej szerokości\n",
    "\n",
    "Parametry:\n",
    "- plain_text (str): Tekst, do którego chcemy dodać ukrytą wiadomość.\n",
    "- secret_message (str): Wiadomość do ukrycia.\n",
    "\n",
    "Zwraca:\n",
    "- encoded_text (str): Tekst oryginalny z dodaną zaszyfrowaną wiadomością."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encrypt(plain_text, secret_message):\n",
    "\n",
    "    # Kodowanie ukrytej wiadomości na postać binarną\n",
    "    binary_message = ''.join(format(ord(char), '08b') for char in secret_message)\n",
    "    zero_width_encoding = binary_message.replace('0', '\\u200B').replace('1', '\\u200C')\n",
    "\n",
    "    # Łączenie tekstu oryginalnego z zakodowaną wiadomością\n",
    "    encoded_text = plain_text + '\\u200D' + zero_width_encoding + '\\u200D'\n",
    "    return encoded_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Funkcja odszyfrowuje ukrytą wiadomość z zakodowanego tekstu.\n",
    "\n",
    "Parametry:\n",
    "- encoded_text (str): Tekst z ukrytą wiadomością.\n",
    "\n",
    "Zwraca:\n",
    "- plain_text (str): Tekst oryginalny bez ukrytej wiadomości.\n",
    "- secret_message (str): Ukryta wiadomość."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def decrypt(encoded_text):\n",
    "    # Sprawdzanie, czy w tekście znajduje się ukryta wiadomość\n",
    "    if '\\u200D' not in encoded_text:\n",
    "        return \"Brak ukrytej wiadomości.\", encoded_text\n",
    "\n",
    "    # Rozdzielanie tekstu oryginalnego i zakodowanej wiadomości\n",
    "    plain_text, encoded_message = encoded_text.split('\\u200D', 1)\n",
    "    encoded_message = encoded_message.strip('\\u200D')\n",
    "\n",
    "    # Konwersja znaków o zerowej szerokości z powrotem do postaci binarnej\n",
    "    binary_message = encoded_message.replace('\\u200B', '0').replace('\\u200C', '1')\n",
    "\n",
    "    # Konwersja binarnej postaci na znaki, aby uzyskać ukrytą wiadomość\n",
    "    secret_message = ''.join(chr(int(binary_message[i:i + 8], 2)) for i in range(0, len(binary_message), 8))\n",
    "\n",
    "    return plain_text, secret_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Przykład użycia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zakodowany tekst: Hello, jak się masz?‍​‌​‌​‌​‌​‌‌​‌​‌‌​‌‌‌​​‌​​‌‌‌‌​​‌​‌‌‌​‌​​​‌‌​​​​‌​​‌‌​​​‌​​‌‌​​‌​​​‌‌​​‌‌‍\n",
      "Tekst oryginalny: Hello, jak się masz?\n",
      "Odszyfrowana wiadomość: Ukryta123\n"
     ]
    }
   ],
   "source": [
    "plain_text = \"Hello, jak się masz?\"\n",
    "secret_message = \"Ukryta123\"\n",
    "\n",
    "# Szyfrowanie\n",
    "encoded_text = encrypt(plain_text, secret_message)\n",
    "print(\"Zakodowany tekst:\", encoded_text)\n",
    "\n",
    "# Odszyfrowanie\n",
    "original_text, decoded_message = decrypt(encoded_text)\n",
    "print(\"Tekst oryginalny:\", original_text)\n",
    "print(\"Odszyfrowana wiadomość:\", decoded_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Druga implementacja**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "from faker import Faker\n",
    "\n",
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "\n",
    "\n",
    "# Function to determine bit based on first letter\n",
    "def letter_to_bit(letter):\n",
    "    vowels = \"AEIOU\"\n",
    "    return '0' if letter.upper() in vowels else '1'\n",
    "\n",
    "\n",
    "# Function to encode a single byte as a department\n",
    "def generate_department(byte):\n",
    "    department = []\n",
    "    bits = f\"{byte:08b}\"  # Convert byte to 8-bit binary string\n",
    "\n",
    "    for i in range(0, 8, 2):  # Each person contributes 2 bits\n",
    "        # Generate random names until we get one with the right first-letter bits\n",
    "        while True:\n",
    "            name = fake.first_name()\n",
    "            surname = fake.last_name()\n",
    "            name_bit = letter_to_bit(name[0])\n",
    "            surname_bit = letter_to_bit(surname[0])\n",
    "\n",
    "            if name_bit == bits[i] and surname_bit == bits[i + 1]:\n",
    "                department.append((name, surname))\n",
    "                break\n",
    "\n",
    "    return department\n",
    "\n",
    "\n",
    "# Function to encode a message into departments\n",
    "def encode_message(message):\n",
    "    byte_array = message.encode('utf-8')  # Encode message to bytes\n",
    "    departments = []\n",
    "\n",
    "    for byte in byte_array:\n",
    "        department = generate_department(byte)\n",
    "        departments.append(department)\n",
    "\n",
    "    return departments\n",
    "\n",
    "\n",
    "# Function to decode the message from departments\n",
    "def decode_message(departments):\n",
    "    bytes_list = []\n",
    "\n",
    "    for department in departments:\n",
    "        bits = \"\"\n",
    "        for name, surname in department:\n",
    "            # Extract bits from the first letters of name and surname\n",
    "            name_bit = letter_to_bit(name[0])\n",
    "            surname_bit = letter_to_bit(surname[0])\n",
    "            bits += name_bit + surname_bit\n",
    "\n",
    "        # Convert 8 bits to a byte and append to the list\n",
    "        byte = int(bits, 2)\n",
    "        bytes_list.append(byte)\n",
    "\n",
    "    # Convert the list of bytes back to the original string\n",
    "    decoded_message = bytes(bytes_list).decode('utf-8')\n",
    "    return decoded_message\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    secret_message = \"Hello\"\n",
    "    encoded_departments = encode_message(secret_message)\n",
    "\n",
    "    print(\"Encoded Departments:\")\n",
    "    for i, department in enumerate(encoded_departments):\n",
    "        print(f\"Department {i + 1}:\")\n",
    "        for name, surname in department:\n",
    "            print(f\"  - {name} {surname}\")\n",
    "\n",
    "    # Decode the message\n",
    "    decoded_message = decode_message(encoded_departments)\n",
    "    print(\"\\nDecoded Message:\", decoded_message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Homoglify**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Program wykorzystuje steganografię tekstową do ukrywania wiadomości w zwykłym tekście poprzez zamianę wybranych liter na ich homoglifowe odpowiedniki z alfabetu cyrylickiego i greckiego. Wiadomość jest konwertowana na ciąg binarny, a następnie kodowana w tekście, zastępując litery zgodnie z wartością bitu (1 → homoglif, 0 → oryginalny znak). Jeśli tekst bazowy jest za krótki, do jego rozszerzenia używany jest model GPT-2, który generuje dodatkową treść. Program umożliwia zarówno zakodowanie, jak i późniejsze odczytanie ukrytej wiadomości, analizując występowanie homoglifów w tekście zakodowanym."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ładowanie modelu GPT-2 i tokenizera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2\" \n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homoglify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOMOGLYPHS = {\n",
    "    # Cyrylica (małe litery)\n",
    "    'a': 'а',  # Cyrylica 'a'\n",
    "    'e': 'е',  # Cyrylica 'e'\n",
    "    'o': 'о',  # Cyrylica 'o'\n",
    "    'p': 'р',  # Cyrylica 'p'\n",
    "    'c': 'с',  # Cyrylica 'c'\n",
    "    'x': 'х',  # Cyrylica 'x'\n",
    "    'y': 'у',  # Cyrylica 'y'\n",
    "\n",
    "    # Grecki (wielkie litery)\n",
    "    'A': 'Α',  # Grecka 'A'\n",
    "    'B': 'Β',  # Grecka 'B'\n",
    "    'E': 'Ε',  # Grecka 'E'\n",
    "    'H': 'Η',  # Grecka 'H'\n",
    "    'I': 'Ι',  # Grecka 'I'\n",
    "    'K': 'Κ',  # Grecka 'K'\n",
    "    'M': 'Μ',  # Grecka 'M'\n",
    "    'N': 'Ν',  # Grecka 'N'\n",
    "    'O': 'Ο',  # Grecka 'O'\n",
    "    'P': 'Ρ',  # Grecka 'P'\n",
    "    'T': 'Τ',  # Grecka 'T'\n",
    "    'X': 'Χ',  # Grecka 'X'\n",
    "    'Y': 'Υ',  # Grecka 'Y'\n",
    "\n",
    "    # Cyrylica (wielkie litery) \n",
    "    'C': 'С',  # Cyrylica 'C'\n",
    "}\n",
    "\n",
    "# Generowanie odwrotnej mapy\n",
    "REVERSE_HOMOGLYPHS = {v: k for k, v in HOMOGLYPHS.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja generująca sensowną kontynuację tekstu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_continuation_with_gpt2(previous_text, max_length=150):\n",
    "    \"\"\"\n",
    "    Generuje sensowną kontynuację tekstu za pomocą modelu GPT-2.\n",
    "    \"\"\"\n",
    "    # Tokenizacja poprzedniego tekstu\n",
    "    input_ids = tokenizer.encode(previous_text, return_tensors='pt')\n",
    "\n",
    "    # Tworzenie maski uwagi (wszystkie tokeny mają wartość 1, bo nie używamy paddingu)\n",
    "    attention_mask = torch.ones(input_ids.shape, device=input_ids.device)\n",
    "\n",
    "    # Generowanie kontynuacji z uwzględnieniem maski uwagi\n",
    "    output = model.generate(input_ids, attention_mask=attention_mask, max_length=max_length, num_return_sequences=1, no_repeat_ngram_size=2, temperature=0.7, do_sample=True, pad_token_id=50256)\n",
    "\n",
    "    # Dekodowanie wyników\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dekodowanie wiadomości:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_message(encoded_text):\n",
    "    \"\"\"\n",
    "    Dekoduje wiadomość z zakodowanego tekstu.\n",
    "    \"\"\"\n",
    "    binary_message = []\n",
    "    \n",
    "    for char in encoded_text:\n",
    "        if char in REVERSE_HOMOGLYPHS:\n",
    "            binary_message.append('1')\n",
    "        elif char in HOMOGLYPHS:\n",
    "            binary_message.append('0')\n",
    "    \n",
    "    # Debug: Wyświetl binarną wiadomość\n",
    "    # print(f\"Odczytana wiadomość binarna: {''.join(binary_message)}\")\n",
    "    \n",
    "    # Grupujemy po 8 bitów (jeden znak w ASCII) i konwertujemy na tekst\n",
    "    message_chars = [\n",
    "        chr(int(''.join(binary_message[i:i+8]), 2))\n",
    "        for i in range(0, len(binary_message), 8)\n",
    "    ]\n",
    "    return ''.join(message_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wywołanie programu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_text = \"Once upon a time, there was a brave hero named Alex.\"\n",
    "hidden_message = \"Ela z mlotkiem w Dubaju\" # mniej więcej maksymalna długośc wiadomości\n",
    "# hidden_message = \"Hi\" \n",
    "\n",
    "try:\n",
    "    # Kodowanie\n",
    "    encoded_text = encode_message(original_text, hidden_message)\n",
    "    print(\"Zakodowany tekst:\", encoded_text)\n",
    "\n",
    "    # Dekodowanie\n",
    "    decoded_message = decode_message(encoded_text)\n",
    "    print(\"Odkodowana wiadomość:\", decoded_message)\n",
    "except ValueError as e:\n",
    "    print(f\"Błąd: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
